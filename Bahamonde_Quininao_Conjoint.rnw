\documentclass[onesided]{article}
\usepackage[T1]{fontenc}
\linespread{1.5} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics

\usepackage[hmarginratio=1:1,columnsep=20pt]{geometry} % Document margins
%\usepackage{multicol} % Used for the two-column layout of the document
\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables
\usepackage{float} % Required for tables and figures in the multi-column environment - they need to be placed in specific locations with the [H] (e.g. \begin{table}[H])

\usepackage{lettrine} % The lettrine is the first enlarged letter at the beginning of the text
\usepackage{paralist} % Used for the compactitem environment which makes bullet points with less space between them

% to ignore texts: good for thank messages and paper submissions.
      % \fbox{\phantom{This text will be invisible too, but a box will be printed arround it.}}

\usepackage{abstract} % Allows abstract customization
\renewcommand{\abstractnamefont}{\normalfont\bfseries} % Set the "Abstract" text to bold
%\renewcommand{\abstracttextfont}{\normalfont\small\itshape} % Set the abstract itself to small italic text

\usepackage[]{titlesec} % Allows customization of titles
\renewcommand\thesection{\Roman{section}} % Roman numerals for the sections
\renewcommand\thesubsection{\Roman{subsection}} % Roman numerals for subsections
\titleformat{\section}[block]{\large\scshape\centering}{\thesection.}{1em}{} % Change the look of the section titles
\titleformat{\subsection}[block]{\large}{\thesubsection.}{1em}{} % Change the look of the section titles

\usepackage{fancybox, fancyvrb, calc}
\usepackage[svgnames]{xcolor}
\usepackage{epigraph}
\usepackage{longtable}
\usepackage{pdflscape}
\usepackage{graphics}
\usepackage{pbox} % \pbox{20cm}{This is the first \\ cell}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{rotating}
\usepackage{paracol}
\usepackage{textcomp}
\usepackage[export]{adjustbox}
\usepackage{afterpage}
\usepackage{filecontents}
\usepackage{color}
\usepackage{latexsym}
\usepackage{lscape}       %\begin{landscape} and \end{landscape}
\usepackage{wasysym}
\usepackage{dashrule}

\usepackage{framed}
\usepackage{tree-dvips}
\usepackage{pgffor}
\usepackage[]{authblk}
\usepackage{setspace}
\usepackage{array}
\usepackage[latin1]{inputenc}
\usepackage{hyperref}     %desactivar para link rojos
\usepackage{graphicx}
\usepackage{dcolumn} % for R tables
\usepackage{multirow} % For multirow in tables
\usepackage{pifont}
\usepackage{listings}




% hypothesis / theorem package begin
\usepackage{amsthm}
\usepackage{thmtools}
\declaretheoremstyle[
spaceabove=6pt, spacebelow=6pt,
headfont=\normalfont\bfseries,
notefont=\mdseries, notebraces={(}{)},
bodyfont=\normalfont,
postheadspace=0.6em,
headpunct=:
]{mystyle}
\declaretheorem[style=mystyle, name=Hypothesis, preheadhook={\renewcommand{\thehyp}{H\textsubscript{\arabic{hyp}}}}]{hyp}

\usepackage{cleveref}
\crefname{hyp}{hypothesis}{hypotheses}
\Crefname{hyp}{Hypothesis}{Hypotheses}
% hypothesis / theorem package end


%----------------------------------------------------------------------------------------
% Other ADDS-ON
%----------------------------------------------------------------------------------------

% independence symbol \independent
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}



% Les principaux ensembles
\newcommand{\Abs}[1]{\left\lvert#1\right\rvert}
\newcommand\N{{\mathbb N}}
\newcommand\R{{\mathbb R}}
\newcommand\T{{\mathbb T}}
\newcommand\C{{\mathbb C}}
\newcommand\Q{{\mathbb Q}}
\newcommand\Z{{\mathbb Z}}
\newcommand\Pp{{\mathbb P}}
\newcommand\Ee{{\mathbb E}}
\def\x{{\mathbf x}}
\def\w{{\mathbf w}}
\def\xxi{{\pmb \xi}}




\hypersetup{
    bookmarks=true,         % show bookmarks bar?
    unicode=false,          % non-Latin characters in Acrobat's bookmarks
    pdftoolbar=true,        % show Acrobat's toolbar?
    pdfmenubar=true,        % show Acrobat's menu?
    pdffitwindow=true,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={My title},    % title
    pdfauthor={Author},     % author
    pdfsubject={Subject},   % subject of the document
    pdfcreator={Creator},   % creator of the document
    pdfproducer={Producer}, % producer of the document
    pdfkeywords={keyword1} {key2} {key3}, % list of keywords
    pdfnewwindow=true,      % links in new window
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=Maroon,          % color of internal links (change box color with linkbordercolor)
    citecolor=Maroon,        % color of links to bibliography
    filecolor=Maroon,      % color of file links
    urlcolor=Maroon           % color of external links
}

%\usepackage[nodayofweek,level]{datetime} % to have date within text

\newcommand{\LETT}[3][]{\lettrine[lines=4,loversize=.2,#1]{\smash{#2}}{#3}} % letrine customization



% comments on margin
  % Select what to do with todonotes: 
  % \usepackage[disable]{todonotes} % notes not showed
  \usepackage[draft]{todonotes}   % notes showed
  % usage: \todo{This is a note at margin}

\usepackage{cooltooltips}

%%% bib begin
\usepackage[american]{babel}
\usepackage{csquotes}
\usepackage[backend=biber,style=authoryear,dashed=false,doi=false,isbn=false,url=false,arxiv=false]{biblatex}
%\DeclareLanguageMapping{american}{american-apa}
\addbibresource{Bahamonde_Quininao_Conjoint.bib} 


% USAGES
%% use \textcite to cite normal
%% \parencite to cite in parentheses
%% \footcite to cite in footnote
%% the default can be modified in autocite=FOO, footnote, for ex. 
%%% bib end


% r code verbatim config
\lstdefinestyle{R}{ %
  language=R,                     % the language of the code
  basicstyle=\footnotesize,       % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it's 1, each line
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  title=\lstname,                 % show the filename of files included with \lstinputlisting;
                                  % also try caption instead of title
  keywordstyle=\color{blue},      % keyword style
  commentstyle=\color{dkgreen},   % comment style
  stringstyle=\color{mauve},      % string literal style
  morekeywords={*,...}            % if you want to add more keywords to the set
}

\lstdefinestyle{Python}{ %
  language=Python,                     % the language of the code
  basicstyle=\footnotesize,       % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\tiny\color{gray},  % the style that is used for the line-numbers
  stepnumber=1,                   % the step between two line-numbers. If it's 1, each line
                                  % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  frame=single,                   % adds a frame around the code
  rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. commens (green here))
  tabsize=2,                      % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
  breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
  title=\lstname,                 % show the filename of files included with \lstinputlisting;
                                  % also try caption instead of title
  keywordstyle=\color{blue},      % keyword style
  commentstyle=\color{dkgreen},   % comment style
  stringstyle=\color{mauve},      % string literal style
  morekeywords={*,...}            % if you want to add more keywords to the set
} 

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}


\lstset{language=R,frame=lines}
\lstset{language=Python,frame=lines}

% DOCUMENT ID



% TITLE SECTION

\title{\vspace{-15mm}\fontsize{18pt}{7pt}\selectfont\textbf{\input{title.txt}\unskip}} % Article title


\author[1]{

\textsc{H\'ector Bahamonde}
\thanks{\href{mailto:hector.bahamonde@uoh.cl}{hector.bahamonde@uoh.cl}; \href{http://www.hectorbahamonde.com}{\texttt{www.HectorBahamonde.com}}.}}



\author[2]{

\textsc{Cristobal Quininao}
\thanks{\href{mailto:cristobal.quininao@uoh.cl}{cristobal.quininao@uoh.cl}; 
\href{https://www.uoh.cl}{\texttt{PAGINA AQUI}}. \\
This project was funded by the Center for \fbox{\phantom{the Experimental Study of Psychology and Politics}} at \fbox{\phantom{Rutgers University---New Brunswick}}. We both thank Richard Lau and David Redlawsk for their comments and suggestions.}}


\affil[1]{Assistant Professor, Instituto de Ciencias Sociales, O$'$Higgins University}
\affil[2]{Assistant Professor, Instituto de Ciencias de la Ingenier\'ia O$'$Higgins University}


\date{\today}

%----------------------------------------------------------------------------------------

\begin{document}
%\SweaveOpts{concordance=TRUE}
% Sweave2knitr("Bahamonde_Quininao_Conjoint.rnw")
\pagenumbering{gobble} 


\setcounter{hyp}{0} % sets hypothesis counter to 1

\maketitle % Insert title


%----------------------------------------------------------------------------------------
% ABSTRACT
%----------------------------------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% loading knitr package

<<echo=FALSE, cache=FALSE, warning = FALSE, message = F>>=
read_chunk('/Users/hectorbahamonde/research/Conjoint_US/Bahamonde_Quininao_Conjoint.R') # Hector path // MAC
# read_chunk('Bahamonde_Quininao_Conjoint.R') % Cristobal path

@


<<rsetup, include=FALSE>>=
chooseCRANmirror(graphics=FALSE, ind=1)
if (!require("pacman")) install.packages("pacman"); library(pacman)
p_load(knitr)
options(scipen = 99999999999)

@

<<constructing:data, echo=FALSE, comment=NA, warning=FALSE, message=FALSE, include = FALSE, cache=FALSE, eval=TRUE>>=

@


<<lapop:bar:chart:data, echo=FALSE, comment=NA, warning=FALSE, message=FALSE, include = FALSE, cache=FALSE, eval=TRUE>>=

@

<<us:map:plot:d, echo=FALSE, comment=NA, warning=FALSE, message=FALSE, include = FALSE, cache=FALSE, eval=TRUE>>=

@


<<amce:plot:d, echo=FALSE, comment=NA, warning=FALSE, message=FALSE, include = FALSE, cache=FALSE, eval=TRUE>>=

@

<<w:analyses:d, echo=FALSE, comment=NA, warning=FALSE, message=FALSE, include = FALSE, cache=FALSE, eval=TRUE>>=

@

<<w:analyses:p:d, echo=FALSE, comment=NA, warning=FALSE, message=FALSE, include = FALSE, cache=FALSE, eval=TRUE>>=

@

<<abstract, echo=FALSE, comment=NA, warning=FALSE, message=FALSE, include = FALSE, cache=FALSE, eval=TRUE>>=

@



% end knitr stuff
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{abstract}
\input{abstract.txt}\unskip
\end{abstract}

\hspace*{1.3cm}{\bf Please consider downloading the last version of the paper} \href{https://github.com/hbahamonde/Conjoint_US/raw/master/Bahamonde_Quininao_Conjoint.pdf}{\texttt{{\color{red}here}}}.

\providecommand{\keywords}[1]{\textbf{\emph{Keywords---}} #1} % keywords.  
\keywords{conjoint designs; vector support machines; support for democracy; United States.}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CONTENT (write the paper below)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newpage
\pagenumbering{arabic}
\setcounter{page}{1}

\section{Toward a Multidimensional Study of Clientelism}

% 1. Democracy is a multidimensional concept.
Democracy has been theorized as a multidimensional concept. Specifically referring to \emph{polyarchies}, \textcite[3]{Dahl1971} explains that full democracies should satisfy a number of dimensions which speak to certain institutional guarantees that create opportunities to (1) formulate political and social preferences, (2) signify those preferences, and (3) have preferences weighted equally when conducting a government. %Since cases where countries are ``completely or almost completely responsive to all its citizens'' are rare, \textcite[8]{Dahl1971} prefers to use the multidimensional concept of \emph{polyarchy}. 

% 2. But the study of clientelism---as a kind of democratic failure \parencite{Kuo2018}---usually is unidimensional. The study of specific conditions that have to fail to produce clientelism is usually focused on a single factor. Perhaps the most studied one is income, and how poverty increases the probability of clientelism. 
Yet, clientelism---as a democracy failure---has been studied almost exclusively from a unidimensional perspective. We believe that there exists a methodological and conceptual alignment---one that biases our inferences. On the one hand, qualitative, historical and/or ethnographically-based contributions describe clientelist transactions as complex and multidimensional. By employing qualitative techniques, researchers are able to provide ``thick descriptions'' \parencite{Goertz1973} of the phenomena at hand \parencite{Posada-Carbo:1996aa,Sabato2001,Auyero2000,Szwarcberg2013,Borges2019}. On the other hand, statistical, survey, and/or experimentally-based work mostly explores singular aspects related to clientelism---typically, the effect of a single variable (or treatment) on the probability of clientelism.\footnote{Quantitative scholars then usually focus on the ``effects of causes'' rather than on the ``causes of effects'' \parencite{Pearl2015}.} For example, using a field experiment in Benin, \textcite{Wantchekon2003} stresses the role of ``incumbency'' on vote buying, while \textcite[227]{Jensen2013a} focus on the impact of ``poverty'' on vote buying. While the quantitative literature on clientelism has advanced on a number of important questions, most studies concentrate their efforts on a single variable which (when possible) is manipulated in an experimental or quasi-experimental design \parencite{Corstange2012a,Imai2014a,Nichter2014a,Hicken2015,Hicken2018,Auerbach2018,Bratton2008a,Weitz-shapiro,GonzalezOcantos2014,Bahamonde2018,Bahamonde2020a,Oliveros2016}. Since the approach (i.e. unicausal/multicausal) is correlated with the method (quantitative/qualitative), we believe this methodological and conceptual alignment represents an important gap in the literature. 

% 3. This paper contributes to the clientelism literature by situating clientelism within a richer and multidimensional conceptualization of democracy by specifying which specific democratic dimensions, when absent, make clientelism more likely.
Substantively, we argue that to better understand the motivations behind clientelism and the micro-dynamics that drive it, studies should situate the phenomena within the \emph{multidimensionality of democracy}. In other words, What are the \emph{causes} of clientelism? Which \emph{dimensions} of democracy---as described by \textcite{Dahl1971}---should fail to produce clientelism? While qualitative researchers are better equipped to properly answer these questions, there are some quantitative techniques that might provide broader explanations for the causes of clientelism. We do not argue that these quantitative tools might give us the kind of rich explanations ethnographies provide. However, we hope this paper provides multidimensional answers to a multidimensional concept within the quantitative framework. Ultimately, this paper tries to provide a multidimensional explanation for clientelism within the ``effects of causes'' approach \parencite{Pearl2015}. Exploiting a novel conjoint dataset, this paper developed an experimental design which sought to answer \emph{Which of the three democratic dimensions explained by \textcite{Dahl1971} should fail to produce clientelism in the United States?} 


Since the vote-buying literature mostly considers developing countries and describes vote sellers as poor \parencite[12]{Weitz-Shapiro:2014aa}, uneducated \parencite{GonzalezOcantos2014}, and undemocratic \parencite{Carlin2015}, the willingness to sell votes in the United States should be low, making it a difficult case study on vote selling.\footnote{However see \textcite{Bahamonde2020a}.} And such, this study follows a ``least-likely'' design presenting the United States as a ``crucial case.'' As \textcite[12]{Levy2008} explains, ``[i]nferential leverage from a least likely case is enhanced if our theoretical priors for the leading alternative explanation make it a most likely case for that theory.'' However, the evidence that this paper presents may be associated with a probable erosion of American democracy \parencite{Levitsky:2018aa}. \textcite[7]{Foa2016a} document a deep ``crisis of democratic legitimacy [that] extends across a [...] wider set of indicators'' in the United States. They find that 26\% of millennials declare that it is ``unimportant'' in a democracy for people to ``choose their leaders in free elections'' (\textcite[10]{Foa2016a} and \textcite{Foa2017b}). Our study aims to contribute to this debate by presenting experimental evidence that links the democracy theory literature with the clientelism literature.

The methodological contribution of this paper is twofolds. First, this paper contributes to the literature by leveraging a conjoint experiment on hypothetical vote selling in the United States, a traditionally considered consolidated democracy. Most quantitative studies have been conducted in developing countries, seriously narrowing the scope of our inferences. In part, this is because the clientelism literature usually focuses on realized behaviors only---that is, actual clientelist transactions. Unfortunately, by ignoring attitudes of \emph{potential} vote sellers, particularly when it comes to the willingness to sell, selection bias seriously threatens causal inferences. \textcite[131]{Geddes1990} explains the well-known selection issues of studying ``only cases that have achieved the outcome of interest.'' Thus, and following the lead of \textcite{GonzalezOcantos2014,Bahamonde2020a}, this paper presents experimental evidence of hypothetical willingness to sell the vote in the United States. 

Second, we introduce machine learning techniques, particularly support vector machine analyses (SVM) for analyzing conjoint datasets. SVMs rely on computational algorithms that solve classification problems in a data-driven fashion. One of the main advantages of SVM methods is that their optimal classification properties are robust even when working with multiple dimensions at the same time. Since this paper makes the case for a multidimensional approach to the study of clientelism, we claim the method is appropriate and relevant to the discipline. From a technical standpoint, SVMs separate groups of observations in a hyperplane. A hyperplane is a geometrical space where observations---survey respondents, in this case---are located. As explained later, the three democracy dimensions described by \textcite{Dahl1971} were operationalized in five different subdimensions (i.e. conjoint attributes). This paper employed SVM methods to group most-similar observations according to their preferences toward the five conjoint attributes. After the classification problem was solved, standard regression techniques were used to study correlations between the preferences of survey participants toward the five conjoint attributes and their willingness to sell the vote---captured by a question asked during the same study. 

We claim this set of techniques might provide new insights about the \emph{specific} democracy dimensions \parencite{Dahl1971} that should fail to make vote selling most likely. In fact, we find that among the five attributes, the only one that ought fail to make vote selling most likely, is the presence of presidential checks and balances. That is, individuals who systematically do not value accountable Presidents, thus preferring a fully autonomous President---one that governs \emph{without} a Congress---are more likely to sell their vote. We believe that this contribution is novel. The authors are not aware of any study in the quantitative literature of clientelism that conceives democracy as a multidimensional concept. In fact, the literature usually assumes that clientelism emerges when ``democracy''---as a whole---fails. This paper takes a step further explaining which \emph{specific} democracy attribute ought to fail to make vote selling most likely. 


The paper continue as follows. \hyperlink{traditional.cj}{First}, we explain the logic of conjoint analyses and their main contribution to political science. \hyperlink{our.cj}{Second}, we introduce a novel dataset of U.S. voters representative at the country level. In that section we \hyperlink{our.cj.classic}{analyze} the conjoint dataset exploiting the traditional conjoint approach and explain its shortcomings. \hyperlink{our.cj.svm}{Third}, we introduce the support vector machine approach to analyzing conjoint data, and proceed to explaining its main advantages and show our main results. Finally, in the \hyperlink{appendix}{Appendix} section we make available \texttt{R} (\autoref{r.code}) and \texttt{Python} (\autoref{p.code}) routines not only to replicate the data analyses in this study, but also to spread these methods among interested researchers, to hopefully move this area of research forward. The \hyperlink{conclusion}{final section} concludes.



\section{Traditional Conjoint Analyses}\hypertarget{traditional.cj}{}

%
% Origins of Conjoint Designs 1
Conjoint designs ask respondents to choose from hypothetical profiles that combine multiple attributes, ``enabling researchers to estimate the relative influence of each attribute value on the resulting choice or rating'' \parencite[2]{Hainmueller2014a}. Typically, survey participants are given a number of ``tasks'' where they have to make a number of choices between---usually---two set of profiles. It is generally accepted that \textcite{Luce1964} started the conjoint design \parencite{Green1978,Franchino2015}. 

% Origins of Conjoint Designs 2
This methodology has been widely used in marketing research to measure ``consumer trade-offs among multi-attributed products and services'' \parencite[174]{Lenk1996}. Typically, researchers in that field would assign arbitrary utilities to investigate ``how much difference each attribute could make in the total utility of a product'' \parencite[79]{Orme2010}. Utilities were assigned according to general expectations, for instance, a ``respondent generally prefers higher gas mileage to lower gas mileage''  \parencite[107]{Green1978}. At the time this seemed particularly interesting given the impossibility to truly randomize the set of attributes. Hence, the analyst needed to set the utilities associated with every attribute in advance, usually building a small number of attribute profiles or ``combinations'' \parencite[175]{Lenk1996}. Much research was done arguing how ranked attributes or attribute ratings were better than using assigned utilities \parencite[301]{Carmone1978}. For instance, \textcite[60]{Louviere2010} criticize the use of arbitrary utilities assigned to every attribute, making traditional conjoint analyses incompatible with economic theory. Since early conjoint methods exploited the ``additive measurements'' of the utilities associated with the respective attribute \parencite[2]{Luce1964}, some times that led to non-accounted-for nonlinearities. 

% Origins of Conjoint Designs 3
A number of topics have been studied, such as preferences for health care \parencite{Ryan2000}, vaccine decision making \parencite{Seanehia2017}, preferences for energy-saving measures \parencite{Poortinga2003}, preferences toward different food packagings \parencite{Silayoi2007a}, consumer demand for fair trade \parencite{Hainmueller2015a}, evaluations of teaching performance \parencite{Kuzmanovic2013}, roommate choice \parencite{Shafranek2019} and renter behavior \parencite{Hankinson2018}. 




% Hainsmuller introduced this technique to political scientists from a Causal Inference perspective
\textcite{Hainmueller2014a} ``introduced conjoint analysis to political science as a survey experimental method for causal inference'' \parencite[1]{Horiuchi2020a}, particularly making conjoint designs compatible with the potential outcomes framework of causal inference \parencite{Rubin1974}. Since then, a number of important studies have been published, making a very common tool for causal inference in political science \parencite{Cuesta2020}. Just to name a few examples in political science, conjoint designs have been used to study attitudes toward immigrants \parencite{Hainmueller2015}, preferences toward political candidates \parencite{Franchino2015,Horiuchi2017,Horiuchi2020,Mares2020}, the role of candidate sex on voter choice \parencite{Ono2019} and the role of the information environment in partisan voting \parencite{Peterson2017}. In part, this is due to the simplicity of the main quantity of interest developed by \textcite[3]{Hainmueller2014a}---the \emph{average marginal component effect} (AMCE).\footnote{Due to space concerns, we are not deriving the AMCE here. The AMCE has been well explained and widely used before. See Equation 5 in \textcite[11]{Hainmueller2014a}. In addition to that, see \textcite{Egami2019}, who have introduced another quantity of interest, the average marginal interaction effect (AMIE).} The quantity equals the counterfactual probability where a specific characteristic would be chosen if the value of that characteristic is absent \parencite[11]{Hainmueller2014a}.\footnote{Importantly, \textcite[6]{Leeper2020} explain that arbitrary choice of reference category when computing the AMCE might introduce ``highly distorted descriptive interpretations of preferences among subgroups of respondents.''} Since the AMCE does not rely on arbitrary utility assignments nor does resort to functional form assumptions \parencite[3]{Hainmueller2014a}, it has become a very common quantity of interest in political science, specially, because it also avoids ``unnecessary statistical assumptions'' at the same time that improves ``internal validity than the more model-dependent procedures'' \parencite[2-3]{Hainmueller2014a}.\footnote{Yet, some necessary assumptions need to be made. For instance, in order to make statistical inferences, the AMCE depends on (clustered) standard errors, which in turn rely on the central limit theorem. See \textcite[17]{Hainmueller2014a}.} Importantly, they show that ``when attribute levels are randomized independently from one another, the ordinary least squares (OLS) estimates of the coefficients from the linear regression of the choice indicator on the set of dummy variables for the levels of the attributes provide unbiased and consistent estimates of the AMCEs'' \parencite[14]{Horiuchi2017}.\footnote{\textcite[15]{Hainmueller2014a} show that OLS estimators have ``identical'' properties to the subclassification estimators, and therefore this ``implies that the linear regression estimator is fully nonparametric.''} Others have argued that when attribute levels are randomized, the design ``reduces social desirability bias by providing many potential reasons for supporting or opposing a proposed [attribute]'' \parencite[7]{Hankinson2018},\footnote{However, see \textcite{Horiuchi2020a}.} while others offer guidance regarding the number of attributes by developing a two-stage conjoint design \parencite{Bansak2019}.


\section{Studying Clientelism Multidimensionally via Conjoint Designs}\hypertarget{our.cj}{}



% Levering on Hainmueller2014a we present our approach
Our multidimensional approach toward the study of vote selling is novel in the quantitative literature. Quantitative contributions on vote buying, vote selling and clientelism in general, are usually unidimensional. Survey experiments have been widely used to study this phenomena. For instance, \textcite{Bahamonde2020a,Gonzalez-Ocantos2012,GonzalezOcantos2014,Gonzalez-Ocantos2015} use list experiments to study the effect of selling prices or specific issues related to norms and legitimacy on the probability of vote selling. While these and other studies have advanced a number of important questions in the discipline, unfortunately, they are able to study one aspect at a time, mainly, by manipulating a word, a sentence, a framing or a price. As \textcite[2]{Hainmueller2014a} point out, these designs ``have an important limitation for analyzing multidimensional decision making.'' We fill this gap by introducing a multidimensional conjoint-based approach to studying vote selling in the United States.


Our contribution builds directly on \textcite{Carlin2011a,Carlin2015,Carlin2017}. Using survey data, they build a series of multidimensional indexes to measure---in Dahlian terms---attitudes towards democracy. Particularly, using the Q-Method and cluster analyses, they account for the multifaceted views towards a democracy. Considering their operationalization strategy of Dahl's conceptualization of democracy (\autoref{tab:dim}) but also leveraging the \textcite{Hainmueller2014a} approach to designing conjoint experiments, we implemented a conjoint design (\autoref{tab:conj:ex}) aimed to studying the multidimensionality of conditions that make vote selling most likely in the United States. Particularly, we are interested in specifying which of the three democracy dimensions of \textcite{Dahl1971} ought to fail to make vote selling most likely in the United States. 


\afterpage{
\begin{table}[h]
\begin{center}
\begin{scriptsize}
{\renewcommand{\arraystretch}{2}%
\scalebox{0.7}{
\begin{tabular}{  c |  m{5cm} | m{5.5cm} }
\toprule
\textbf{Dahl's Polyarchy Dimension} & \textbf{Dahl's Requirements for a Democracy} & \textbf{Experimental Operationalization for Conjoint Design} \\
\midrule
\multirow{5}{*}{{\bf Formulate preferences}}               & Freedom of expression                             & Media can confront the government                      \\\cline{2-3} 
                                                           & Alternative sources of information                & Media can confront the government                      \\\cline{2-3}
                                                           & Right of political leaders to compete for support & President cannot rule without Congress                    \\\cline{2-3}
                                                           & Right to vote                                     & Citizens can vote in the next two elections            \\\cline{2-3}
														                               & Freedom to form and join organizations            & Citizens can associate with others and form groups     \\\cline{2-3}
\hline
\multirow{7}{*}{{\bf Signify preferences}}                 & Freedom of expression                             & Media can confront the government\\ \cline{2-3}
                                                           & Alternative sources of information                & Media can confront the Government\\ \cline{2-3}
                                                           & Right of political leaders to compete for support & President cannot rule without Congress\\ \cline{2-3}
                                                           & Right to vote                                     & Citizens can vote in the next two elections\\ \cline{2-3}
                                                           & Free and fair elections                           & Citizens can vote in the next two elections\\ \cline{2-3}
                                                           & Eligibility for public office                     & Citizens can run for office for the next two elections\\ \cline{2-3}
														                               & Freedom to form and join organizations            & Citizens can associate with others and form groups\\ \cline{2-3}
\hline
\multirow{8}{*}{\pbox{3.5cm}{{\bf Preferences are weighted} \\ {\bf equally in conduct of government}}} & Freedom of expression & Media can confront the government\\ \cline{2-3} 
                                                           & Alternative sources of information                & Media can confront the Government\\ \cline{2-3}
                                                           & Right of political leaders to compete for support/votes & President cannot rule without Congress\\ \cline{2-3}
                                                           & Right to vote                                     & Citizens can vote in the next two elections\\ \cline{2-3}
                                                           & Free and fair elections                           & Citizens can vote in the next two elections \\ \cline{2-3}
                                                           & Institutions for making government policies depend on votes and other expressions of preference & Citizens can vote in the next two elections\\\cline{2-3}
                                                           & Eligibility for public office                     & Citizens can run for office for the next two elections\\ \cline{2-3}
														                               & Freedom to form and join organizations & Citizens can associate with others and form groups\\ 
                                                           
\bottomrule
\end{tabular}}}
\end{scriptsize}
\caption{{\bf Dimensions of Democracy \parencite{Dahl1971} and Their Corresponding Experimental Operationalizations.} \\\hspace{\textwidth} {\bf Note}: \textcite{Dahl1971} specifies three general dimensions that should be satisfied for a country to be considered democratic (first column). Every dimension has a number of requirements (second column). Based on \textcite{Carlin2011a,Carlin2015,Carlin2017}, we operationalized these requirements for the conjoint experiment by devising five attributes (third column). As \autoref{tab:conj:ex} shows, all participants were asked to choose between hypothetical candidates that either supported or rejected each of these five attributes.}\label{tab:dim}
\end{center}
\end{table}
}


% ``The study of politics is to a significant extent the study of multidimensional choices'' Hainmueller2014a 1


% Our conjoint
Conjoint designs are suitable tools to ``determine which components of the manipulation produce the observed effect'' \parencite[2]{Hainmueller2014a}. Following \textcite{Dahl1971}, \autoref{tab:dim} specifies three general dimensions that should be satisfied for a country to be considered democratic (first column). Every dimension has a number of requirements (second column). Based on \textcite{Carlin2011a,Carlin2015,Carlin2017}, we operationalized these requirements for the conjoint experiment by devising five attributes (third column): (1) \emph{media can confront the government}, (2) \emph{president cannot rule without congress}, (3) \emph{citizens can vote in the next two elections}, (4) \emph{citizens can run for office for the next two elections} and (5) \emph{citizens can associate with others and form groups}. 

\afterpage{
\begin{table}[h]
\begin{center}
{\renewcommand{\arraystretch}{2}%
%\scalebox{1}{
\begin{tabular}{cc}
\hline
\multicolumn{2}{|m{16cm}|}{\texttt{In the next section you will see 10 different candidates presented in pairs.  Each candidate supports different policies.  Some candidates might or might not share some similarities/differences.  You might not like any of them, but we want to know which candidate represents the lesser of the two evils for you. You might want to focus your attention on the issues that you care about the most.}}\\ \hline
\multicolumn{1}{|c|}{{\bf Candidate 1}}   & \multicolumn{1}{c|}{{\bf Candidate 2}}  \\ \hline
\multicolumn{1}{|c|}{\small{Media CAN confront the government}}    & \multicolumn{1}{c|}{\small{Media CANNOT confront the government}}   \\ \hline
\multicolumn{1}{|c|}{\small{President CANNOT rule without Congress}}    & \multicolumn{1}{c|}{\small{President CAN rule without Congress}}   \\ \hline
\multicolumn{1}{|c|}{\small{Citizens CANNOT vote in the next two elections}}    & \multicolumn{1}{c|}{\small{Citizens CANNOT vote in the next two elections}}   \\ \hline
\multicolumn{1}{|c|}{\small{Citizens CAN run for office for the next two elections}}    & \multicolumn{1}{c|}{\small{Citizens CAN run for office for the next two elections}}   \\ \hline
\multicolumn{1}{|c|}{\small{Citizens CAN associate with others and form groups}}    & \multicolumn{1}{c|}{\small{Citizens CANNOT associate with others and form groups}}   \\ \hline
\multicolumn{2}{c}{\texttt{Which of these candidates represents the lesser of the two evils for you?}} \\ \hline
\multicolumn{1}{|c|}{\texttt{Candidate 1} {\large$\square$}} & \multicolumn{1}{c|}{\texttt{Candidate 2} {\large$\square$}} \\ \hline
\end{tabular}}
\caption{{\bf A Multidimensional Approach to Studying Clientelism: A Conjoint Design (example).} \\\hspace{\textwidth} {\bf Note}:  Participants were asked to choose between two hypothetical candidates (\texttt{Candidate 1} and \texttt{Candidate 2}). Every entry was filled at random according to the five different attributes explained in \autoref{tab:dim}. In practice, every subject chose between two unique hypothetical candidates. Note that in order to highlight the differences between the two candidates, the \emph{can} and \emph{cannot} were capitalized. The idea was to minimize experimental fatigue.}\label{tab:conj:ex}
%}
\end{center}
\end{table}
}

% the design: possible problems of unlikely scenarios
Given that conjoint designs are able ``to identify the causal effects of various components of a treatment in survey experiments'' \parencite[2]{Hainmueller2014a}, we claim that this is an appropriate tool to shed some light on the multi-causal study of clientelism. To study which democratic dimension(s) should fail to produce clientelism, we presented subjects (as in \autoref{tab:conj:ex}) two hypothetical candidates that supported (or not) every policy (attribute)---as operationalized in \autoref{tab:dim}. We recognize that the resulting candidate profiles are highly unlikely. Unlikely profiles (such as doctors with no education) have been a big concern in the conjoint literature. So far the suggestion has been to delete them before hand by restricting randomization of certain unlikely profiles \parencite{Hainmueller2014a} or by marginalizing ``factors over the target population distribution'' via the population AMCE \parencite[12]{Cuesta2020}. While acknowledging the advantages of both approaches, our goal is identifying a set of democratic attributes that, when absent, make clientelism more likely. In fact, external validity seems to be the trade-off when building a case study according to the \emph{least}-likely case design \parencite{Levy2008}. In addition, one of the methodological contributions of this paper is to overcome selection bias by studying \emph{hypothetical} behaviors, specially the ones where the outcome of interest has not been produced \parencite{Geddes1990}. And finally, there are several survey experiments that have fielded hypothetical questions, mostly putting respondents in experimental conditions that do not necessarily mimic reality. For instance, \textcite{Bahamonde2020a} finds that a big portion of U.S. voters would be willing to sell their vote to an hypothetical candidate in exchange for money, while \textcite{Ballard-Rosa2017} examine a number of tax proposals ``that are infeasible in the real world politics'' \parencite[5]{Cuesta2020}. %Nonetheless, in order to minimize possible concerns of external validity, survey participants were asked to choose \emph{which candidate represented the lesser of the two evils} for them. 

\autoref{tab:conj:ex} shows one possible realization of the experiment. It is important to note that every attribute was randomly assigned, and consequently, every participant in practice chose between two unique hypothetical candidates. Also, in order to minimize experimental fatigue, the \texttt{CAN} and \texttt{CANNOT} were capitalized.

% the flow and the framing of the experiment.
The study considered a \hyperlink{direct.question}{direct question} about the intention to sell the vote. As a whole, the conjoint experiment was framed as a study about crime in the United States, not as a study about clientelism. Participants were asked to read \hyperlink{distractor.vignette}{an excerpt} mentioning a number of crimes. All were formatted as news pieces. The idea was to explain ``vote selling'' to ``newsreaders.'' To further prevent bias, the direct question stated that there was the hypothetical possibility of doing one of the illegal things mentioned in the excerpt. And that this possibility would be randomly assigned. However, all participants were directly asked whether they would be interested in selling their vote. Following \textcite{Bahamonde2020a}, to capture the willingness to sell without the potential costs, participants were asked whether they would be willing to accept the offer, assuming they would not go to jail. After answering the conjoint portion of the study, participants were asked to answer a battery of socio-demographic and political questions. 


Ultimately, our design will allow a series of hypotheses tests between every of the five democracy attributes and the vote selling question. Typical conjoint analyses offer descriptive associations between hypothetical attributes. While these analyses have advanced a number of important research avenues, they do not permit statistical associations between the selected profiles and the respondents attitudes or preferences. By introducing support vector machine techniques to analyzing conjoint experiments, we are able to do so. As we explain later, this approach improves our causal inferences by permitting statistical correlations between the selected conjoint profiles (democracy) and the respondents attitudes (vote selling). We also are able to control for other observables (the socio-demographic battery). Before presenting the machine learning approach, we first present our novel dataset and analyzes it first by using the traditional AMCE-based conjoint approach. 


\subsection{Classic Conjoint Data Approach}\hypertarget{our.cj.classic}{}{}

% barplot:figure:control:treatment
% LAPOP Bar Chart
<<us:map:plot, echo = FALSE, fig.pos='H', warning = FALSE, message = F, fig.cap=us.map.note, fig.align='center', fig.width=10, fig.height=5,dpi=100000,cache=FALSE, include = TRUE>>=


@

Collected in 2016, the data (N=\Sexpr{total.sample.size.c}) are representative at the national level.\footnote{\Sexpr{total.sample.size.c} respondents, everyone answering \Sexpr{tasks} tasks with \Sexpr{candidates} candidates each. \emph{Research Now SSI} collected the data between March 2 and March 6 2016. Survey respondents belong to the online panel owned and administered by SSI. Notice of IRB exemption Protocol \#E16-292 is kept on file at the Office of Research and Regulatory Affairs of \fbox{\phantom{Rutgers}} University.}  \autoref{fig:us:map:plot} shows the geographical distribution of survey respondents grouped by party identification.  Following \textcite{Hainmueller2014a}, we computed the AMCE via the OLS estimator using clustered standard errors. In this section we present a classic conjoint analysis. Particularly, we show the hypothetical candidates' attributes that were selected by survey respondents. 


% amce:plot
<<amce:plot, echo = FALSE, fig.pos='H', warning = FALSE, message = F, fig.cap=amce.plot.note, fig.align='center', fig.width=10, fig.height=5,dpi=1000,cache=FALSE, include = TRUE>>=


@


\autoref{fig:amce:plot} suggests that respondents systematically preferred hypothetical candidates who supported democratic policies. Authoritarian candidates that can rule without Congress, or political systems in which there is controlled mass media, or where citizens are not allowed to vote, run for office or associate with others, are systematically rejected by the nationally represented pool of respondents. These analyses are not surprising as they conform with our theoretical priors, i.e. the United States has (traditionally) been considered a strong democracy. 

While classic conjoint analyses provide consistent causal estimates, they unfortunately overlook respondent's preferences. As \autoref{fig:amce:plot} suggests, analysts can \emph{describe} aggregate behaviors but cannot establish relationships between the respondent's preferences and her attribute choices. In other words, analysts are not able to tell a story of \emph{why} respondents choose what they chose. By implementing support vector machine methods we are able to introduce additional covariates---such as respondent socio-economic and political preferences---and explore the reasons that make vote selling more likely in the United States. Why we still believe description is ``good science'' \parencite{Gerring2012a}, the descriptive nature of the classic conjoint design (for instance, via the AMCE) might (wrongly) suggest that democratic values scored high in the United States. After all, \autoref{fig:amce:plot} strongly indicates that non-democratic candidate attributes are systematically rejected (i.e. all coefficients are negative). And as a consequence, that might imply that the intention to sell the vote should be low. The ability to introduce covariates, such as the intention to sell the vote,  might shed some light about how healthy or broken democratic values were at the time were the data were collected (which coincides with the campaign period that gave Donald Trump the U.S. presidency). We claim this is an exceptional opportunity to study democracy, and particularly, the democratic attitudes that, when broken, explain vote selling. Next section introduces support vector machine methods that allow analyzing conjoint data considering subject preferences and/or attitudes. 

% In fact, the \href{https://www.vanderbilt.edu/lapop/usa/2010_United_States_Questionnaire.pdf}{LAPOP} 2010 survey wave for the United States suggests that \Sexpr{percentage.never}\% of respondents has never been asked to sell the vote. 


\section{Introducing Support Vector Machines Methods to Analyzing Conjoint Data}\hypertarget{our.cj.svm}{}

Support vector machine methods are a subclass of machine learning techniques, which in turn are a branch of the artificial intelligence field. The main goal of these methods is to use computational algorithms to learn from data \parencite{talabis2015analytics}. For instance, in agricultural sciences machine learning methods are used to identify between crops and grass using satellite images as data. There are mainly three branches of machine learning techniques: supervised learning, unsupervised learning and reinforcement learning. Based on a subset\todo{decia set, ok?} of the complete dataset (the ``training'' dataset), the goal of supervised learning is to identify \todo{decia find, ok?} a mathematical function able to map a vector (``input'') to another vector (``output'') based on input-output data pairs which are used as examples. For instance, the analyst can define how crops and grass look like (output). Once the mathematical function is defined, supervised learning techniques should be able to automatically recognize newly presented images of crops and grass (input) and classify them (map) into their respective categories (output)---i.e. ``grass'' or ``crops.'' Unsupervised learning is similar to supervised learning, but the training dataset have only the input component. Thus, the computational algorithms in this case should be able to find patterns in the dataset without having prior information. Finally, reinforcement learning was inspired by behavioral psychology, and its main goal is to determine what actions an algorithm should perform in order to maximize some notion of ``accumulated reward.''

Support vector machines (SVMs) are a set of techniques of supervised learning which might be extended to classification applications and/or standard regression techniques \parencite[Ch. 12]{maimon2005data}. In this paper we are interested in applying SVM methods to---first---solve a classification problem, and then in a second stage, apply OLS methods. The first stage is a data-driven process which consists of defining a full set of democratic attitudes, and then finding a classification rule (i.e. a mathematical function) that takes survey participants and classify them along the constructed democratic attitudes spectrum. In particular, we are interested in learning about the political preferences of survey participants by using the information participants provided when making choices between the two hypothetical candidates and the policies those candidates endorsed (as exemplified in \autoref{tab:conj:ex}). Since the focus is to account for the multi-dimensionality of democracy, we perform these analyses for all five democracy attributes. In the second stage we use standard regression methods to study correlations between the five democracy attributes (obtained in the first stage) and respondent's socio-political attitudes, particularly, the willingness to sell the vote. In sum, we exploit the conjoint dataset to first classify all participants within a common space for all five attributes. Then we fit five separate OLS regression models between those five spaces and the willingness to sell the vote (controlling for relevant covariates).

\paragraph{Stating the problem} Consider the following classification task: estimate a function $f:\R^J\rightarrow\{-1,1\}$ using a system of input-output training data pairs. The $f$ function should be able to map every participant attitudes toward the five democracy attributes and classify those attitudes within a common numeric space. 


As exemplified in \autoref{tab:conj:ex}, all hypothetical political candidates took stances in favor (or against) the five democracy policies. For an input $\mathbf x\in\{0,1\}^5$, which represents the range of possible political stances of a candidate, the function $f$ maps survey participants with all democracy attributes\todo{hb: consistencia de que son todos los attributes}, linking both in what could be described as the ``decision'' made by the survey participant. For instance, hypothetical candidates 1 and 2 in \autoref{tab:conj:ex} are represented by vectors $(1,1,0,1,1)$ and $(0,0,0,1,0)$, respectively. Then, the function $f$ connects the respondent's attribute choices (embodied by hypothetical candidates $1$ or $2$) with the respondent herself (i.e. her ``decision''). 

\paragraph{Constructing the vector weight $\mathbf w^i$} One way to motivate our approach is via the latent variable and the standard maximization utility approaches. For simplicity, we assume that participant preferences can be modeled by an additive linear utility function, and that the decision function $f$ takes a utility sign $\{+, -\}$ depending on the attribute chosen---more details are provided below. If the data can be partitioned by an hyperplane (which is the case in most randomized conjoint designs), such functions can be defined for every participant $i$.

Survey participants evaluate between two hypothetical candidates and choose one. They do so for all five tasks. To clarify, for a survey participant $i$, we have the following conjoint data,

\begin{equation}
(\mathbf x_1^{1,i},\mathbf x_1^{2,i};y_{1}^i),\,\,(\mathbf x_2^{1,i},\mathbf x_2^{2,i};y_{2}^i),\,\,\ldots\,\, (\mathbf x_5^{1,i},\mathbf x_5^{2,i};y_{5}^i)
\end{equation}



where $\mathbf x_k^{1,i}$ represents the attributes of candidate 1 shown to citizen $i$ during task $k$. Similarly, $\mathbf x_k^{2,i}$ represents the attributes of candidate 2 shown to citizen $i$ during task $k$. The corresponding $y_k$ is the selected candidate. We coded $y_k^i=1$ when survey participant $i$ selected candidate $1$, and $y_k^{i}=-1$ when survey participant $i$ selected candidate $2$. Since we are trying to characterize a linear function for every $i$, survey participants can be mapped by a vector weight $\mathbf w^i\in\mathbb R^5$ and an intercept $b^i$. Indeed, for a candidate $\mathbf x$, the function,

\begin{equation}
u_i(\mathbf x) = \w^i\cdot\mathbf x+b,
\end{equation}

models the utility function of every survey participant $i$. For consistency, we identify weights $\w^i\in\R^5$ and intercept $b\in\R$ such that,

\begin{equation}\label{eq:unoGana}
\w^i\cdot(\mathbf x_k^{1,i}-\mathbf x_k^{2,i}) > 0 \quad\Leftrightarrow\quad y_k^i=1,
\end{equation}


and

\begin{equation}\label{eq:dosGana}
\w^i\cdot(\mathbf x_k^{1,i}-\mathbf x_k^{2,i}) < 0 \quad\Leftrightarrow\quad y_k^i=-1,
\end{equation}

implying that whenever two candidates $\mathbf x_1^{1,i}$ and $\mathbf x_1^{2,i}$ are presented, the survey respondent will choose the one that provides him with a larger utility.


\paragraph{Optimization strategy} Note that, within this framework, it is sufficient to consider the differences between the democracy attributes among the two hypothetical candidates. In fact, the selected hypothetical candidate and their corresponding policy stands are observed quantities. {\color{red}This is slightly different from the question: for a candidate $\mathbf x$ should you select her?}\todo{?} Therefore, and from a theoretical standpoint, unlike $u_i$ which cannot be directly constructed, $\w^i$ is the only observed quantity of interest which is accessed within the space of differences between candidates. We define then the {\color{red}centered coordinates}\todo{?} $\mathbf z^i_k\in\{-1,0,1\}$ as,

\begin{equation}
\mathbf z^i_k=\mathbf x_k^{1,i}-\mathbf x_k^{2,i},
\end{equation}

hence, from now on, the intercept $b$ will be ignored because a function of the type $f_i(\mathbf z_k)=\text{sign}(\w_i\cdot\mathbf z^i_k)$ is mathematically sufficient. Indeed, equations \autoref{eq:unoGana} and \todo{decia ``-''} \autoref{eq:dosGana} become,

\begin{equation}
y_k^i\left(\w^i\cdot \mathbf z_k^i\right) > 0,
\end{equation}

It should be clear by now that the challenge is to identify weights $\w^i$ for every survey participant $i$. Under the data separability assumption, it has been shown by \textcite{vapnik1991necessary} that it suffices to focus on the margin, defined as {\color{red}the minimal distance of a sample to the decision surface}\todo{rephrase this}. For notation simplicity, the dependence of $y^i$ and $\mathbf z_k^i$ on $i$ will be dropped. By rescaling $\w_i$ we know that the closest {\color{red}points to the hyperplane} must satisfy,

\begin{equation}
|\w^i\cdot\mathbf z_k| = 1,
\end{equation}

and if two observations $\mathbf z_k$ and $\mathbf z_m$ belong to different classes (i.e. selected candidate), then the margin is defined as the distance of these two {\color{red}points to the hyperplane},

\begin{equation}
\frac{\w^i}{\|\w^i\|} \cdot(\mathbf z_k-\mathbf z_m) = \frac{2}{\|\w^i\|}.
\end{equation}

It should be clear by now that for each survey participant $i$, the optimal hyperplane is the solution to the following optimization problem,

\begin{equation}\label{eq:restriction}
\min_{\w^i}\frac12\|\w^i\|^2
\text{subject to} \; y_k\,(\w^i\cdot \mathbf z_k)\geq 1,\,\, k=1,2,3,4,5.
\end{equation}

Regarding the actual dataset analyzed in this study, it is unknown if these data can be separated by an hyperplane. To allow for bad classification issues, \textcite{cortes1995support} introduced the concept of ``slack variables'' $\xi_i$ that relax the optimization problem restrictions (\autoref{eq:restriction}):

\begin{equation}
y_k\,( \w^i\cdot\mathbf z_k)\geq 1-\xi_k,\quad \xi_k\geq0,\quad k=1,2,3,4,5.
\end{equation}

All in all, this allows controlling for both the classification strength of $\|\w^i\|$, and the sum of the slack variables $\sum_{k=1}^5 \xi_k$ which account for possible classification deviations. \todo{explicar aqui el trade-off} A widely used solution to that trade-off is the $C$-SVM, or ``soft margin classifying,'' which is based on the minimization of the following objective function,

\begin{equation}
\min_{\w^i,\xi}\frac12\|\w^i\|^2+C\sum_{k=1}^5\xi_k,
\end{equation}

where the regularization constant $C>0$ determines the trade-off between the empirical error and the {\color{red}complexity term}\todo{explayar}. The optimization problem was solved using the \texttt{sklearn} library in \texttt{Python}.\todo{explayar ``steepest descent approach''}\footnote{See \autoref{p.code}. We also make available an \texttt{R} routine that directly solves the optimization problem by using the {\color{red}steepest descent approach} (see \autoref{r.code}).} Since the optimization problem is convex, algorithms converge to a unique solution.


\subsection{Analyzing The Conjoint Data via Support Vector Machines}

Based on \autoref{w:analyses:t}, \autoref{fig:w:analyses:p:p} shows {\color{red}PENDING}.\footnote{\autoref{summary:stats:t} shows summary statistics.}

<<density:plot:w:p, echo = FALSE, fig.pos='H', warning = FALSE, message = F, fig.cap=density.plot.w.p.note, fig.align='center', fig.width=8, fig.height=2,dpi=1000,cache=FALSE, include = TRUE>>=


@


<<w:analyses:p:p, echo = FALSE, fig.pos='H', warning = FALSE, message = F, fig.cap=w.analyses.p.note, fig.align='center', fig.width=12, fig.height=10,dpi=1000,cache=FALSE, include = TRUE>>=


@

\todo{hb:}




\section{Conclusion}\hypertarget{conclusion}{}
\todo{hb: to do}


% References
\newpage
\pagenumbering{Roman}
\setcounter{page}{1}
\printbibliography





% EndNotes
%\newpage
%\pagenumbering{Roman}
%\setcounter{page}{1}
%\linespread{2} % 1.5, Line spacing - Palatino needs more space between lines
%\theendnotes
%\linespread{1.5} % 1.5, Line spacing - Palatino needs more space between lines




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% WORD COUNT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage

<<wordcount, echo=FALSE, cache=FALSE, warning=FALSE>>=
library(knitr)

comma <- function (x, ...) {
  format(x, ..., big.mark = ",", scientific = FALSE, trim = TRUE)
}

# To dynamically extract name of the current file, use code below
nameoffile <- current_input() # get name of file
nof2 <-  strsplit(nameoffile,"\\.")[[1]][1] # extract name, drop extension
noftex <- paste(nof2, ".tex", sep="") # add .tex extension
systemcall <- paste("system('texcount -inc -incbib -total -sum ", noftex, "', intern=TRUE)", sep="") # paste together texcount system command
texcount.out <- eval(parse(text=systemcall)) # run texcount on current last compiled .tex file

sum.row <- grep("Sum count", texcount.out, value=TRUE) # extract row
pattern <- "(\\d)+" # regex pattern for digits

count <- regmatches(sum.row, regexpr(pattern, sum.row) )
# extract digits

count <- comma(as.numeric(count)) # add comma
@


\begin{center}
\vspace*{\stretch{1}}
\dotfill
\dotfill {\huge {\bf Word count}: \Sexpr{count}} \dotfill
\dotfill
\vspace*{\stretch{1}}
\end{center}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% WORD COUNT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





% reset counter for appendix
%% reset tables and figures counter
\setcounter{table}{0}
\renewcommand{\thetable}{A\arabic{table}}
\setcounter{figure}{0}
\renewcommand{\thefigure}{A\arabic{figure}}

\newpage
\pagenumbering{Roman}
\setcounter{page}{1}

\section{Appendix}\hypertarget{appendix}{}



\subsection{Experimental Manipulations and Vignettes}


\paragraph{Distractor Paragraph.} \hypertarget{distractor.vignette}{The next paragraph was used to distract subjects} from the main purpose of the study, and also to define vote selling. After reading the excerpt, participants were told about the hypothetical possibility of doing one of the illegal things mentioned in the excerpt. And that this possibility would be randomly assigned. However, all participants were directly asked whether they would be interested in selling their vote (as seen on \hyperlink{direct.question}{Direct Question}.

\begin{lstlisting}[frame=lrtb, breaklines=true, breakatwhitespace=true]
Washington, D.C.- A department store downtown had a robbery incident last week, reporting several missing iPods from their inventory. Authorities also inform that a group of local residents are trying to ``sell'' their votes to political candidates ahead of a local election for city council. Residents approached some of the candidates running for office and offered to vote for that candidate in return for monetary compensation. In a different subject matter, the local police station released a report on driving habits and behaviors in the Capitol district last week. Finally, cyber-crime has become an increasingly serious issue in the area in the past few year.
\end{lstlisting}


\newpage
\paragraph{Direct Question.} \hypertarget{direct.question}{All subjects} read the next paragraph, and then \emph{all} answered the direct question:

\begin{lstlisting}[frame=lrtb, breaklines=true, breakatwhitespace=true]
Now you will be entered into a random lottery for the opportunity to do ONE of the illegal things you just read before. This means that you might be randomly offered to hypothetically do ANY of the activities mentioned before.
\end{lstlisting}


\begin{lstlisting}[frame=lrtb, breaklines=true, breakatwhitespace=true]
After a random assignment, you have been selected for the opportunity to hypothetically sell your vote. This means that you will have the hypothetical opportunity to accept money from a candidate for your vote. Would you be willing to accept the offer, assuming you would not go to jail? By selecting ``Yes,'' you could earn up to $ 1,000.
\end{lstlisting}
\vspace*{\fill}
\pagebreak


\newpage
\subsection{Summary Statistics}


<<summary:stats:t, echo = FALSE, results='asis', warning = FALSE, message = F,cache=F, include = TRUE>>=

@
\pagebreak


\newpage
\subsection{Algorithms}

\lstinputlisting[label={r.code}, caption={R SVM Algorithm}, style=R]{svm_script.R}

\lstinputlisting[label={p.code}, caption={Python SVM Algorithm}, style=Python]{svm_script.py}


\newpage
\subsection{Regression Table: OLS Analyses using the SVM Approach to Analyzing Conjoint Data}


<<w:analyses:t, echo = FALSE, results='asis', warning = FALSE, message = F,cache=F, include = TRUE>>=

@
\pagebreak


\newpage
\subsection{Algorithms}


Consider the following set of training data-pairs $\left\{(\mathbf z_k,y_k)\right\}_{k=1}^n$ with $\mathbf z_k\in\R^2$ and $y_k\in\{-1,1\}$. We look for an hyperplane going through the origin such that,

\begin{equation}
\mathbf w \cdot \mathbf z_k > 0\quad\Leftrightarrow\quad y_k=1
\qquad\text{and}\qquad\mathbf w \cdot \mathbf z_k < 0\quad\Leftrightarrow\quad y_k=-1,
\end{equation}

in the case of $z_k\in\R^2$ we have that such hyperplane is simply a straight line with a 0 intercept,

\begin{equation}
L(\mathbf z) := L((z_1,z_2)) = w_1z_1+w_2z_2.
\end{equation}

Now, if $z_k=(z_{k,1},z_{k,2})$, then we look for $\mathbf w$ such that,

\begin{equation}\label{eq:problem}
y_k\left(w_1 z_{k,1} + w_2z_{k,2} \right) >0,\qquad \forall k=1,\ldots,n.
\end{equation}


Since $n\in\N$ is fixed, there must be some $\delta=\delta(\mathbf w)$ such that,

\begin{equation}
\delta = \min_{k=1,\ldots,n}y_k\left(w_1 z_{k,1} + w_2z_{k,2} \right) >0,
\end{equation}

therefore, by redefining $\mathbf w = \mathbf w/\delta$, equation \autoref{eq:problem} cab be rewritten as,

\begin{equation}
y_k\left(w_1 z_{k,1} + w_2z_{k,2} \right) > 1
\end{equation}

moreover, the points $\mathbf z_k$ closest to $L(\mathbf z)$ can be defined such that,

\begin{equation}
y_k\left(w_1 z_{k,1} + w_2z_{k,2} \right) = 1.
\end{equation}


Recall that the distance between a point $\mathbf z=(z_1,z_2)\in\R^2$ to the line $L$ is given by,

\begin{equation}
\text{distance}(\mathbf z,L) = \frac{|w_1z_1+w_2z_2|}{\sqrt{w_1^2+w_2^2}}.
\end{equation}

Let $(z_{k,1},z_{k,2})$ a training data-pair belonging to the class labeled $+1$, and $(z_{m,1},z_{m,2})$ a training data-pair belonging to the class labeled $-1$. Assume furthermore that $(z_{k,1},z_{k,2})$ is one of the points in the $1$ class that is closest to the optimal hyperplane. Similarly, assume that $(z_{m,1},z_{m,2})$ is one of the points in the $-1$ class that is closest to the optimal hyperplane. The margin is defined as the sum of the distances between $(z_{k,1},z_{k,2})$ and $(z_{m,1},z_{m,2})$ to the optimal hyperplane. That is,

\begin{equation}
\text{margin} = \frac{|w_1z_{k,1}+w_2z_{k,2}|}{\sqrt{w_1^2+w_2^2}}+\frac{|w_1z_{m,1}+w_2z_{m,2}|}{\sqrt{w_1^2+w_2^2}}
\end{equation}

since $y_k=1$ then we have that,

\begin{equation}
y_k\left(w_1 z_{k,1} + w_2z_{k,2} \right) = w_1 z_{k,1} + w_2z_{k,2} = 1>0
\end{equation}

and

\begin{equation}
y_m\left(w_1 z_{m,1} + w_2z_{m,2} \right) = -\big(w_1 z_{m,1} + w_2z_{m,2}\big) = 1>0
\end{equation}

therefore, we can rewrite the margin as,

\begin{equation}
\text{margin} = \frac{w_1z_{k,1}+w_2z_{k,2}}{\sqrt{w_1^2+w_2^2}}-\frac{w_1z_{m,1}+w_2z_{m,2}}{\sqrt{w_1^2+w_2^2}} = \frac{(w_1,w_2)\cdot(z_{k,1}-z_{m,1},z_{k,2}-z_{m,2})}{\sqrt{w_1^2+w_2^2}},
\end{equation}

or simply by $\frac{\w}{\|\w\|} \cdot(\mathbf z_k-\mathbf z_m)=\frac{2}{\|\w\|}$. To find the optimal hyperplane is, in this example, to find the values of $w_1$ and $w_2$ such that the margin is the largest possible. This is achieved with the vector $\mathbf w$ with smallest norm, and we find out the optimization problem stated in the main text,

\begin{eqnarray*}
&&\min_{\w}\frac12\|\w^i\|^2
\\
\text{subject to} && y_k\,(\w\cdot \mathbf z_k)\geq 1,\,\, k=1,\ldots,n.
\end{eqnarray*}

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{example_hyperplane}
\caption{Two dimensional example of the optimal hyperplane. Red dots correspond to the training data-points labeled as -1, and the blue dots correspond to the training data-points labeled as +1. The margin is defined as the sum of the distance between points in different classes to the hyperplane.}
\end{figure}
\pagebreak



% Notes
\linespread{2}
%\newpage\theendnotes


\end{document}

